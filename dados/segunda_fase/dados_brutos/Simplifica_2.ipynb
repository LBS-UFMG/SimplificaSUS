{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a090b6",
   "metadata": {},
   "source": [
    "# Importação das bibliotecas utilizadas:\n",
    "\n",
    "* `pandas` biblioteca utilizada para tabulação e tratamento de dados\n",
    "* `googletrans` biblioteca não oficial utilizada para tradução automática utilizando o Google Translate\n",
    "* `numpy` biblioteca utilizada para agilizar e otimizar operações numéricas durante o processamento\n",
    "* `re` biblioteca utilizada para busca de expressões regulares e tratamento de strings (texto)\n",
    "* `json` biblioteca utilizada para geração do JSON que abastece as visualizações (_front end_)\n",
    "* `pymed` biblioteca utilizada para busca e coleta automatizada de artigos científicos da base PubMED\n",
    "* `vaderSentiment` biblioteca com modelos pré-treinados para classificação de texto (sentiment analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ebebf1-ae6d-49ae-b702-861ae876381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googletrans import Translator\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from pymed import PubMed\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaa0996",
   "metadata": {},
   "source": [
    "# Passo 1 - Inicialização do pymed e pesquisa inicial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7d15e95-afc5-4f9d-b93c-1cf95db1603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284609\n"
     ]
    }
   ],
   "source": [
    "email = 'fcc-pesquisas@hotmail.com'\n",
    "query = '(Sars-cov2 OR COVID OR nCOV)'\n",
    "#query = 'Monkeypox'\n",
    "pubmed = PubMed(tool=\"PyMed\", email=\"fcc-pesquisas@hotmail.com\")\n",
    "n = pubmed.getTotalResultsCount(query=query)\n",
    "results = pubmed.query(query, max_results=99999999999)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba50c13",
   "metadata": {},
   "source": [
    "# Passo 2 - Carregamento da base de dados de fármacos, qualis e H-Index\n",
    "\n",
    "Um dos pilares da solução proposta é a identificação dos fármacos citados e a classificação das fontes segundo seu impacto e qualidade. Para isso, utilizamos a última atualização do qualis (avaliação de 2019) e o H-Index, segundo a plataforma [Scimago](https://www.scimagojr.com/journalrank.php). \n",
    "\n",
    "Para a identificação dos fármacos, utilizamos os nomes comerciais e nomes de princípios ativos de milhares de medicamentos aprovados pela FDA e também aqueles listados no DrugCentral. Para a maioria dos medicamentos, também são verificadas suas abreviações (ex: HCQ = Hydroxichloroquine, TCZ = Tocilizumabe, etc.). Além destes medicamentos, foram adicionados manualmente os termos `vaccine` e  `convalescent plasma`, pois se tratam de termos mais genéricos, mas que se encaixam no escopo do projeto aqui desenvolvido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "398a5ab2-0200-4e7f-807b-43400902c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passo 2 - Carregar base de dados de fármacos, qualis e H-Index\n",
    "with open('Dados/drug-drugsfda-0001-of-0001.json') as file:\n",
    "    fda = json.load(file)\n",
    "to_lower = lambda x: x.lower()\n",
    "farmacos = pd.read_csv('Dados/DrugCentral/drug.target.interaction.tsv.gz',sep='\\t')\n",
    "farm = [f.lower() for f in pd.unique(farmacos['DRUG_NAME'])]\n",
    "druglist = []\n",
    "for entry in fda['results']:\n",
    "    if 'products' in entry.keys():\n",
    "        drugs = entry['products']\n",
    "        for d in drugs:\n",
    "            names = [d['brand_name']]\n",
    "            for ig in d['active_ingredients']:\n",
    "                names.append(ig['name'])\n",
    "    druglist.extend(names)\n",
    "druglist = [d.lower() for d in pd.unique(druglist)]\n",
    "farm.extend(['vaccine','convalescent plasma'])\n",
    "farm.extend(druglist)\n",
    "farm.remove('0')\n",
    "farm = pd.unique(farm)\n",
    "qualis = pd.read_csv('Dados/qualis2019.csv', delimiter=';')\n",
    "qualis['TITULO'] = qualis['TITULO'].apply(to_lower)\n",
    "sjr = pd.read_csv('Dados/scimago.csv',delimiter=';')\n",
    "sjr['Title'] = sjr['Title'].apply(to_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ebafd",
   "metadata": {},
   "source": [
    "# Passo 3 - Tabulação dos resultados, tradução e classificação\n",
    "\n",
    "Nesta etapa, partimos dos resultados retornados pela API `pymed`, e os processamos, transformando-os em uma tabela contendo resumo, resumo traduzido, metadados da publicação, extrato qualis da publicação, H-index, fármacos citados favoravelmente e fármacos citados desfavoravelmente. Esta última classificação é realizada utilizando _sentiment analysis_ utilizando, por hora, um modelo pré-treinado.\n",
    "\n",
    "É importante ressaltar que, como estamos tratando com dados textuais, todos os textos foram convertidos para minúsculo. Pontuações também foram removidas para evitar confusão durante a fase de _sentiment analysis_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator(service_urls=['translate.google.com'])\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "base = dict.fromkeys(['titulo', 'resumo','resumo_traduzido', 'revista', 'data', 'qualis', 'H-index','doi', 'tipo'],[np.nan]*n) | dict.fromkeys(['pro', 'contra', 'indefinido'],[np.nan]*n) \n",
    "base = pd.DataFrame(base)\n",
    "k = 0\n",
    "for r in results:\n",
    "    base.at[k,'titulo'] = r.title\n",
    "    try:\n",
    "        base.at[k,'resumo'] = r.abstract\n",
    "    except:\n",
    "        continue\n",
    "    try:\n",
    "        base.at[k,'doi'] = r.doi\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        translation = translator.translate(r.abstract, dest='pt')\n",
    "        base.at[k,'resumo_traduzido'] = translation.text\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        base.at[k,'resultados'] = r.results\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        base.at[k,'revista'] = r.journal\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        base.at[k, 'data'] = r.publication_date\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        base.at[k, 'H-index'] = sjr.loc[sjr['Title']==r.journal.lower(),'H index'].values[0]\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        base.at[k, 'qualis'] = qualis.loc[qualis['TITULO']==r.journal.lower(),'ESTRATO'].values[0]\n",
    "    except:\n",
    "        pass\n",
    "    if isinstance(r.abstract, str):\n",
    "        nota = {}\n",
    "        usados = []\n",
    "        if isinstance(r.title, str):\n",
    "            texto = to_lower(' '.join([r.title,r.abstract]))\n",
    "        else:\n",
    "            texto = to_lower(r.abstract)\n",
    "        if 'systematic review' in texto:\n",
    "            base.at[k,'tipo'] = 'revisão sistemática'\n",
    "        elif 'meta analysis' in texto or 'meta-analysis' in texto:\n",
    "            base.at[k,'tipo'] = 'meta análise'\n",
    "        elif 'case report' in texto:\n",
    "            base.at[k,'tipo'] = 'estudo de caso'\n",
    "        elif 'cohort' in texto:\n",
    "            base.at[k,'tipo'] = 'estudo de coorte'\n",
    "        elif 'clinical trial' in texto:\n",
    "            base.at[k,'tipo'] = 'estudo clínico randomizado'\n",
    "        else:\n",
    "            base.at[k,'tipo'] = 'outros'\n",
    "        frases = re.split('\\; |\\.|\\n',texto)\n",
    "        for i in range(len(frases)):\n",
    "            palavras = frases[i].replace('\\n', ' ').replace('.', '').replace(',','').split()\n",
    "            for j in range(len(palavras)):\n",
    "                t = palavras[j]\n",
    "                if (t in farm):\n",
    "                    if t not in usados:\n",
    "                        usados.append(t)\n",
    "                        nota[t] = 0\n",
    "                    nota[t] += analyzer.polarity_scores(frases[i])['compound']\n",
    "        for t in usados:\n",
    "            if nota[t] > 0.25:\n",
    "                if isinstance(base.at[k,'pro'], list):\n",
    "                    base.at[k,'pro'].append(t)\n",
    "                else:\n",
    "                    base.at[k,'pro'] = [t]\n",
    "            elif nota[t] < -0.25:\n",
    "                if isinstance(base.at[k,'contra'], list):\n",
    "                    base.at[k,'contra'].append(t)\n",
    "                else:\n",
    "                    base.at[k,'contra'] = [t]\n",
    "            else:\n",
    "                if isinstance(base.at[k,'indefinido'], list):\n",
    "                    base.at[k,'indefinido'].append(t)\n",
    "                else:\n",
    "                    base.at[k,'indefinido'] = [t]\n",
    "    else:\n",
    "        base.at[k,'tipo'] = 'indefinido'\n",
    "    k +=1\n",
    "    if k > n:\n",
    "        break\n",
    "    text = np.round(100*k/n,2)\n",
    "    print(f'{\"|\"*int(text) + \"-\"*(100-int(text))}  {text}%', end='\\r')\n",
    "print(f'{\"|\"*100} 100.00%')\n",
    "base.to_csv('Pymed_CVD.csv')\n",
    "valid = base.loc[(~base['pro'].isnull()) | (~base['contra'].isnull()) | (~base['indefinido'].isnull())]\n",
    "valid.to_csv('Pymed_validos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08096266",
   "metadata": {},
   "source": [
    "# Passo 4 - Processamento dos resultados para geração do dashboard\n",
    "\n",
    "Nesta etapa, os resultados tabulados são processados para alimentar o dashboard. Aqui são contados os arquivos que descrevem positivamente ou negativamente os resultados encontrado. A classificação do tipo de estudo é realizada diretamente no _front end_, permitindo a visualização de um dashboard com filtros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "71a518fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_list = []\n",
    "con_list = []\n",
    "ind_list = []\n",
    "for i in range(len(valid)):\n",
    "    if isinstance(valid.at[i,\"pro\"], list): \n",
    "        pro_list.extend(valid.at[i,\"pro\"])\n",
    "    elif isinstance(valid.at[i,\"pro\"], str): \n",
    "        pro_list.extend(eval(valid.at[i,\"pro\"]))\n",
    "    if isinstance(valid.at[i,\"contra\"], list):\n",
    "        con_list.extend(valid.at[i,\"contra\"])\n",
    "    elif isinstance(valid.at[i,\"contra\"], str):\n",
    "        con_list.extend(eval(valid.at[i,\"contra\"]))\n",
    "    if isinstance(valid.at[i,\"indefinido\"], list):\n",
    "        ind_list.extend(valid.at[i,\"indefinido\"])\n",
    "    elif isinstance(valid.at[i,\"indefinido\"], str):\n",
    "        ind_list.extend(eval(valid.at[i,\"indefinido\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "76b2f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tecnologias = pro_list.copy()\n",
    "tecnologias.extend(con_list)\n",
    "tecnologias.extend(ind_list)\n",
    "tecnologias = pd.unique(tecnologias)\n",
    "tec = {\"tecnologia\":[], \"pro\":[], \"contra\":[]}\n",
    "for t in tecnologias:\n",
    "    tec[\"tecnologia\"].append(t)\n",
    "    tec[\"pro\"].append(pro_list.count(t))\n",
    "    tec[\"contra\"].append(con_list.count(t) + ind_list.count(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9f1ac0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tec = pd.DataFrame(tec)\n",
    "tec = tec.sort_values(by=['pro','contra'],ascending = [False,True])\n",
    "tec = tec.loc[(tec[\"pro\"]>1)|(tec[\"contra\"]>1)]\n",
    "tec.transpose().to_csv(\"cvd_pymed.csv\",sep=\";\",index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
